{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e4aeea-f631-425a-ac92-8955b01dfa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.43it/s]\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "#Author: Nicolas Martin \n",
    "#This is a low-memory version of Flux for GPUs<16GB,\n",
    "#use image fractalapps/genimages:v0815a to have everything ready (see readme.md)\n",
    "\n",
    "#As Flux Dev is an open source version, its results are not so good as the dev and the pro versions.\n",
    "#Nevertheless, you can generate several renders to improve your chances to have a great result.\n",
    "\n",
    "import torch\n",
    "\n",
    "from diffusers import  FluxPipeline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from optimum.quanto import freeze, qfloat8, quantize\n",
    "\n",
    "from diffusers import FlowMatchEulerDiscreteScheduler, AutoencoderKL\n",
    "from diffusers.models.transformers.transformer_flux import FluxTransformer2DModel\n",
    "from diffusers.pipelines.flux.pipeline_flux import FluxPipeline\n",
    "from transformers import CLIPTextModel, CLIPTokenizer,T5EncoderModel, T5TokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4539c4d-3278-42fd-b17d-25bb919f773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://gist.github.com/VvanGemert/ab9c3ce63f12d429cf6075dbd764e57c\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# schnell is the distilled turbo model. For the CFG distilled model, use:\n",
    "# bfl_repo = \"black-forest-labs/FLUX.1-dev\"\n",
    "# revision = \"refs/pr/3\"\n",
    "#\n",
    "\n",
    "#bfl_repo = \"black-forest-labs/FLUX.1-schnell\"\n",
    "bfl_repo = \"/gen_model/\"\n",
    "revision = \"refs/pr/1\"\n",
    "\n",
    "scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(bfl_repo, subfolder=\"scheduler\", revision=revision)\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=dtype)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=dtype)\n",
    "text_encoder_2 = T5EncoderModel.from_pretrained(bfl_repo, subfolder=\"text_encoder_2\", torch_dtype=dtype, revision=revision)\n",
    "tokenizer_2 = T5TokenizerFast.from_pretrained(bfl_repo, subfolder=\"tokenizer_2\", torch_dtype=dtype, revision=revision)\n",
    "vae = AutoencoderKL.from_pretrained(bfl_repo, subfolder=\"vae\", torch_dtype=dtype, revision=revision)\n",
    "transformer = FluxTransformer2DModel.from_pretrained(bfl_repo, subfolder=\"transformer\", torch_dtype=dtype, revision=revision)\n",
    "\n",
    "# Experimental: Try this to load in 4-bit for <16GB cards.\n",
    "#\n",
    "# from optimum.quanto import qint4\n",
    "# quantize(transformer, weights=qint4, exclude=[\"proj_out\", \"x_embedder\", \"norm_out\", \"context_embedder\"])\n",
    "# freeze(transformer)\n",
    "quantize(transformer, weights=qfloat8)\n",
    "freeze(transformer)\n",
    "\n",
    "quantize(text_encoder_2, weights=qfloat8)\n",
    "freeze(text_encoder_2)\n",
    "\n",
    "pipe = FluxPipeline(\n",
    "    scheduler=scheduler,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    text_encoder_2=None,\n",
    "    tokenizer_2=tokenizer_2,\n",
    "    vae=vae,\n",
    "    transformer=None,\n",
    ")\n",
    "pipe.text_encoder_2 = text_encoder_2\n",
    "pipe.transformer = transformer\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c8dec5-2d8d-4999-a54a-9e41b912e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picture's dimensions\n",
    "height=768\n",
    "width=1360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ffdd20e-46a4-4330-b58f-b2fc1a94952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Inference part A\n",
    "\n",
    "#Here, we create several random renders from the same prompt with a precise naming based on the seed and the date.\n",
    "\n",
    "\n",
    "prompt = \"hyper realistic Earth from satellite centered on India\"\n",
    "\n",
    "renders = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,renders):\n",
    "\n",
    "    seed = random.randint(10000, 99999)\n",
    "\n",
    "    print(seed)\n",
    "    \n",
    "    out = pipe(\n",
    "        prompt=prompt,\n",
    "        guidance_scale=0.,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=4,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(seed),\n",
    "        max_sequence_length=256,\n",
    "    ).images[0]\n",
    "    \n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # Format the date and time as Month_Day_HH_MM_SS\n",
    "    formatted_time = now.strftime(\"%m_%d_%H_%M_%S\")\n",
    "    \n",
    "    image_name = formatted_time + \"_\" + str(seed) + \"_\" + str(i) + \"_A.png\"\n",
    "    out.save(image_name)\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cced05b-8fdd-440f-8957-d7746db88758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Inference part B\n",
    "\n",
    "prompt = 'a sport motorbike with \"CHECK\" printed in green, hyper realistic, exposition background'\n",
    "\n",
    "renders = 6\n",
    "\n",
    "for i in range(0,renders):\n",
    "\n",
    "    seed = random.randint(10000, 99999) #15000 + i #\n",
    "\n",
    "    print(seed)\n",
    "    \n",
    "    out = pipe(\n",
    "        prompt=prompt,\n",
    "        guidance_scale=0.,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=4,\n",
    "        generator=torch.Generator(\"cpu\").manual_seed(seed),\n",
    "        max_sequence_length=256,\n",
    "    ).images[0]\n",
    "    \n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # Format the date and time as Month_Day_HH_MM_SS\n",
    "    formatted_time = now.strftime(\"%m_%d_%H_%M_%S\")\n",
    "    \n",
    "    image_name = formatted_time + \"_\" + str(seed) + \"_\" + str(i) + \"_B.png\"\n",
    "    out.save(image_name)\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18cf09c8-6ca2-463b-bd1e-644ff0235f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Inference part C\n",
    "\n",
    "prompt = 'A futuristic rocket takes off, high angle, extreme close up from top, fire effects, ground background, hyper realistic'\n",
    "\n",
    "renders = 7\n",
    "\n",
    "\n",
    "for i in range(0,renders):\n",
    "\n",
    "    seed = random.randint(10000, 99999) #15000 + i #\n",
    "\n",
    "    print(seed)\n",
    "    \n",
    "    out = pipe(\n",
    "        prompt=prompt,\n",
    "        guidance_scale=0.,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=4,\n",
    "        generator=torch.Generator(\"cpu\").manual_seed(seed),\n",
    "        max_sequence_length=256,\n",
    "    ).images[0]\n",
    "    \n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # Format the date and time as Month_Day_HH_MM_SS\n",
    "    formatted_time = now.strftime(\"%m_%d_%H_%M_%S\")\n",
    "    \n",
    "    image_name = formatted_time + \"_\" + str(seed) + \"_\" + str(i) + \"_C.png\"\n",
    "    out.save(image_name)\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c66047-4a1d-4770-b9ac-0445b3667694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f03b7-526e-471e-8c4c-18108a752a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
